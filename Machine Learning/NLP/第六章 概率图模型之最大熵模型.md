# 最大熵模型

## 最大熵原理

最大熵的本质就是，在满足已有事实的基础上，选择哪个熵最大的模型(因为满足约束的模型有无数个)

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/最大熵.png)

## 定义

最大熵模型是判别式模型，最终是对条件概率P(y|x)建模，但我们对x和y的分布一无所知，因此要用到x,y的联合概率的经验分布，以及x的边缘概率的经验分布。

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/经验分布.png)

对于约束，需要通过特征函数来体现(**这里的经过特征函数得到的特征与以往的算法里不太一样，以往的算法用到的特征是从
x里提取出来的，这里提取的是x和y的特征**)

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/特征函数.png)

通常会定义多个这样的特征函数。同意条样本可能会激活多个特征函数，同一个特征函数可能被多条样本激活，因此，通过特征函数来确定约束条件需要使用期望来定义.

特征函数关于经验分布的期望：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/期望1.png)

特征函数关于模型和x的边缘分布的经验分布的期望：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/期望2.png)

如果模型可以从数据中提取信息，那么就可以假设这两个期望相等：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/期望相等.png)

**最大熵的定义如下：**

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/定义.png)

## 学习

最大熵的学习过程就是求解最大熵的过程。具体就是，通过拉格朗日方法将约束最优化问题转为无约束最优化，然后求解无约束优化的对偶问题。

约束优化：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/约束优化.png)。

转化为求最小值：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/约束优化2.png)

无约束优化：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/无约束优化.png)

原始问题及对偶问题：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/原始问题对偶问题.png)

由于朗格朗日函数是凸函数，因此原始问题和对偶问题的解是等价的。具体求解如下：

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/求解1.png)

![image](D:/Program/YNote/workspace/gorpel@163.com/Picture/求解2.png)


**改进的迭代尺度法：**

TODO